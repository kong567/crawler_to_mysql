version: '3.0'  # 使用 Docker Compose 的版本 3.0，適合大部分部署場景

services:

  crawler_cnyes_headlines:  # 定義一個服務，名稱為 crawler_twse

    image: "${DOCKER_IMAGE_FULL}" # 使用的映像檔名稱與標籤（版本）

    hostname: "cnyes_headlines"  # 設定 hostname = twse
    command: pipenv run celery -A crawler.worker worker -Q cnyes_headlines --loglevel=info --hostname=%h  
    # 啟動容器後執行的命令，這裡是啟動 Celery worker，指定 app 為 crawler.worker，設定日誌等級為 info，
    # 使用主機名稱當作 worker 名稱（%h），並將此 worker 加入名為 "twse" 的任務佇列 (queue)
    # volumes:
    #   - /home/delight/All_crawler:/All_crawler  # 掛整個專案碼目錄
    #   - /home/delight/All_crawler/crawler_data/crawler_cnyes_headlines_data:/All_crawler/data/cnyes_headlines  # 掛資料
    restart: always  # 若容器停止或崩潰，自動重新啟動
    environment:
      - TZ=Asia/Taipei  # 設定時區為台北（UTC+8）
    networks:
      - my_network  # 將此服務連接到 my_network 網路


  
  ETF_historyprice:  # 定義一個服務，名稱為 crawler_twse

    image: "${DOCKER_IMAGE_FULL}" # 使用的映像檔名稱與標籤（版本）

    hostname: "historyprice"  # 設定 hostname = twse
    command: pipenv run celery -A crawler.worker worker -Q historyprice --loglevel=info --hostname=%h  
    # 啟動容器後執行的命令，這裡是啟動 Celery worker，指定 app 為 crawler.worker，設定日誌等級為 info，
    # 使用主機名稱當作 worker 名稱（%h），並將此 worker 加入名為 "twse" 的任務佇列 (queue)
    # volumes:
    #   - /home/delight/All_crawler:/All_crawler
    #   - /home/delight/All_crawler/crawler_data/ETF_historyprice_data:/All_crawler/data/historyprice
    restart: always  # 若容器停止或崩潰，自動重新啟動
    environment:
      - TZ=Asia/Taipei  # 設定時區為台北（UTC+8）
    networks:
      - my_network  # 將此服務連接到 my_network 網路




  PremiumDiscount:  # 定義一個服務，名稱為 crawler_twse

    image: "${DOCKER_IMAGE_FULL}"  # 使用的映像檔名稱與標籤（版本）

    hostname: "PremiumDiscount"  # 設定 hostname = twse
    command: pipenv run celery -A crawler.worker worker -Q PremiumDiscount --loglevel=info --hostname=%h  
    # 啟動容器後執行的命令，這裡是啟動 Celery worker，指定 app 為 crawler.worker，設定日誌等級為 info，
    # 使用主機名稱當作 worker 名稱（%h），並將此 worker 加入名為 "twse" 的任務佇列 (queue)
    # volumes:
    #    - /home/delight/All_crawler:/All_crawler
    #    - /home/delight/All_crawler/crawler_data/ETF_PremiumDiscount_data:/All_crawler/data/premium_discount
    restart: always  # 若容器停止或崩潰，自動重新啟動
    environment:
      - TZ=Asia/Taipei  # 設定時區為台北（UTC+8）
    networks:
      - my_network  # 將此服務連接到 my_network 網路




  MagaBank_NEWS:  # 定義一個服務，名稱為 crawler_twse

    image: "${DOCKER_IMAGE_FULL}"  # 使用的映像檔名稱與標籤（版本）

    hostname: "MagaBank_NEWS"  # 設定 hostname = twse
    command: pipenv run celery -A crawler.worker worker -Q MagaBank_NEWS --loglevel=info --hostname=%h  
    # 啟動容器後執行的命令，這裡是啟動 Celery worker，指定 app 為 crawler.worker，設定日誌等級為 info，
    # 使用主機名稱當作 worker 名稱（%h），並將此 worker 加入名為 "twse" 的任務佇列 (queue)
    # volumes:
    #    - /home/delight/All_crawler:/All_crawler
    #    - /home/delight/All_crawler/crawler_data/MagaBank_NEWS_data:/All_crawler/data/magabank
    restart: always  # 若容器停止或崩潰，自動重新啟動
    environment:
      - TZ=Asia/Taipei  # 設定時區為台北（UTC+8）
    networks:
      - my_network  # 將此服務連接到 my_network 網路


  PTT:  # 定義一個服務，名稱為 crawler_twse

    image: "${DOCKER_IMAGE_FULL}"  # 使用的映像檔名稱與標籤（版本）

    hostname: "PTT_news"  # 設定 hostname = twse
    command: pipenv run celery -A crawler.worker worker -Q PTT_news --loglevel=info --hostname=%h  
    # 啟動容器後執行的命令，這裡是啟動 Celery worker，指定 app 為 crawler.worker，設定日誌等級為 info，
    # 使用主機名稱當作 worker 名稱（%h），並將此 worker 加入名為 "twse" 的任務佇列 (queue)
    # volumes:
    #   - /home/delight/All_crawler:/All_crawler
    #   - /home/delight/All_crawler/crawler_data/ptt_data:/All_crawler/data/ptt
        
    restart: always  # 若容器停止或崩潰，自動重新啟動
    environment:
      - TZ=Asia/Taipei  # 設定時區為台北（UTC+8）
    networks:
      - my_network  # 將此服務連接到 my_network 網路



  vix:  # 定義一個服務，名稱為 crawler_twse

    image: "${DOCKER_IMAGE_FULL}"  # 使用的映像檔名稱與標籤（版本）

    hostname: "VIX"  # 設定 hostname = twse
    command: pipenv run celery -A crawler.worker worker -Q VIX --loglevel=info --hostname=%h  
    # 啟動容器後執行的命令，這裡是啟動 Celery worker，指定 app 為 crawler.worker，設定日誌等級為 info，
    # 使用主機名稱當作 worker 名稱（%h），並將此 worker 加入名為 "twse" 的任務佇列 (queue)
    # volumes:
    #   - /home/delight/All_crawler:/All_crawler
    #   - /home/delight/All_crawler/crawler_data/vix_data:/All_crawler/data/vix

    restart: always  # 若容器停止或崩潰，自動重新啟動
    environment:
      - TZ=Asia/Taipei  # 設定時區為台北（UTC+8）
    networks:
      - my_network  # 將此服務連接到 my_network 網路




networks:
  my_network:
    # 加入已經存在的網路
    external: true
